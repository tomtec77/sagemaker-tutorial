{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "developing-tenant",
   "metadata": {},
   "source": [
    "# Tutorial: Build, Train and Deploy a ML Model with SageMaker\n",
    "\n",
    "In this example we'll build, train and deploy a machine learning model using the XGBoost algorithm. Amazon SageMaker is a fully managed service that manages all the infrastructure required to build and deploy machine learning (ML) models quickly and at scale.\n",
    "\n",
    "The goal of the exercise is to predict whether a bank customer will enroll for a certificate of deposit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-reporter",
   "metadata": {},
   "source": [
    "## Environment and libraries\n",
    "\n",
    "The first step is to import the required libraries and define the environment variables you need to prepare the data, and to train and deploy the ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "little-bristol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success - the MySageMakerInstance is in the us-east-1 region. You will use the 811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest container for your SageMaker endpoint.\n"
     ]
    }
   ],
   "source": [
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "from sagemaker import get_execution_role\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "# Define IAM role\n",
    "role = get_execution_role()\n",
    "prefix = 'sagemaker/DEMO-xgboost-dm'\n",
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:latest'} # each region has its XGBoost container\n",
    "my_region = boto3.session.Session().region_name    # Set the region of the instance\n",
    "print(\"Success - the MySageMakerInstance is in the \" + my_region + \" region. You will use the \" +\n",
    "     containers[my_region] + \" container for your SageMaker endpoint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-implementation",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "The data used here is the Bank Marketing Data Set (https://archive.ics.uci.edu/ml/datasets/bank+marketing) that contains information on customer demographics, responses to marketing events, external factors, and a column which identifies whether the customer is enrolled for a product offered by the bank.\n",
    "\n",
    "Start by preprocessing the data and uploading it to an Amazon S3 bucket. We'll create the bucket here. The bucket name must be unique - if you don't receive a success message after running the code, change the bucket name and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "crucial-tuning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 bucket created successfully\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'sagemaker-tutorial-bucket-1234'\n",
    "s3 = boto3.resource('s3')\n",
    "try:\n",
    "    if my_region == 'us-east-1':\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "    else:\n",
    "        s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={ 'LocationConstraint': my_region })\n",
    "    print('S3 bucket created successfully')\n",
    "except Exception as e:\n",
    "    print('S3 error: ', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-edinburgh",
   "metadata": {},
   "source": [
    "Download the data to your SageMaker instance and load the data into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unavailable-madness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: downloaded bank_clean.csv.\n",
      "Success: data loaded into dataframe.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    urllib.request.urlretrieve(\"https://d1.awsstatic.com/tmt/build-train-deploy-machine-learning-model-sagemaker/bank_clean.27f01fbbdf43271788427f3682996ae29ceca05d.csv\", \"bank_clean.csv\")\n",
    "    print('Success: downloaded bank_clean.csv.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ', e)\n",
    "    \n",
    "try:\n",
    "    model_data = pd.read_csv('./bank_clean.csv', index_col=0)\n",
    "    print('Success: data loaded into dataframe.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-tiffany",
   "metadata": {},
   "source": [
    "Shuffle and split the data into training data (70% of the total data available) and test data (the remaining 30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stunning-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7*len(model_data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-madness",
   "metadata": {},
   "source": [
    "## Train the ML model\n",
    "\n",
    "We'll use the training dataset to train a ML model. First we have to reformat the header and first column of the training data, then load from the S3 bucket. This step is required to use the SageMaker pre-built XGBoost algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "exterior-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([train_data['y_yes'], train_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('train.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-nerve",
   "metadata": {},
   "source": [
    "Set up the Amazon SageMaker session, create an instance of the XGBoost model (an estimator) and define the model's hyperparameters, then start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "appreciated-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "xgb = sagemaker.estimator.Estimator(containers[my_region], role, instance_count=1, instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket_name, prefix), sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(max_depth=5, eta=0.2, gamma=4, min_child_weight=6, subsample=0.8, silent=0,\n",
    "                        objective='binary:logistic', num_round=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-egyptian",
   "metadata": {},
   "source": [
    "Start training the model using gradient optimization on a `ml.m4.xlarge` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "junior-effects",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-20 23:23:00 Starting - Starting the training job...\n",
      "2021-04-20 23:23:25 Starting - Launching requested ML instancesProfilerReport-1618960980: InProgress\n",
      "......\n",
      "2021-04-20 23:24:25 Starting - Preparing the instances for training.........\n",
      "2021-04-20 23:25:45 Downloading - Downloading input data...\n",
      "2021-04-20 23:26:26 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2021-04-20:23:26:27:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2021-04-20:23:26:28:INFO] Path /opt/ml/input/data/validation does not exist!\u001b[0m\n",
      "\u001b[34m[2021-04-20:23:26:28:INFO] File size need to be processed in the node: 3.38mb. Available memory size in the node: 8413.57mb\u001b[0m\n",
      "\u001b[34m[2021-04-20:23:26:28:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[23:26:27] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[23:26:28] 28831x59 matrix with 1701029 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.100482\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.099858\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.099754\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.099095\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.098991\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.099303\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.099684\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.09906\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.098852\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.098679\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.098748\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.098748\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.098748\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.09854\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.098574\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.098609\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.098817\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.098817\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.098679\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.098679\u001b[0m\n",
      "\u001b[34m[23:26:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.098713\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.098505\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.098401\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.098332\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.098332\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.09795\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.098262\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.098193\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 24 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.097985\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.097499\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.097638\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.097395\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.097222\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.097118\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.097014\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.09684\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.096667\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.096736\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.096563\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.096355\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 36 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.096285\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 38 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.096528\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 16 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.096355\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.096459\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 36 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.096355\u001b[0m\n",
      "\u001b[34m[23:26:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 34 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.096216\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.096077\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.0958\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.095904\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.095904\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 34 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.095834\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[51]#011train-error:0.095765\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[52]#011train-error:0.095904\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[53]#011train-error:0.095834\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[54]#011train-error:0.095834\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[55]#011train-error:0.09573\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[56]#011train-error:0.095626\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[57]#011train-error:0.095696\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[58]#011train-error:0.095661\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 24 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[59]#011train-error:0.095592\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[60]#011train-error:0.095522\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 16 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[61]#011train-error:0.095383\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 20 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[62]#011train-error:0.095314\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[63]#011train-error:0.095661\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 32 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[64]#011train-error:0.095661\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[65]#011train-error:0.095418\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 36 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[66]#011train-error:0.095314\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[67]#011train-error:0.095349\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 28 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[68]#011train-error:0.095314\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 28 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[69]#011train-error:0.095314\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 32 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[70]#011train-error:0.095383\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[71]#011train-error:0.095453\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[72]#011train-error:0.095349\u001b[0m\n",
      "\u001b[34m[23:26:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 24 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[73]#011train-error:0.095245\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[74]#011train-error:0.095175\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 18 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[75]#011train-error:0.095071\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[76]#011train-error:0.095175\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[77]#011train-error:0.095002\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 20 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[78]#011train-error:0.095037\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 32 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[79]#011train-error:0.095037\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[80]#011train-error:0.095002\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[81]#011train-error:0.094794\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[82]#011train-error:0.094759\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[83]#011train-error:0.094933\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[84]#011train-error:0.09469\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[85]#011train-error:0.094759\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[86]#011train-error:0.094482\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[87]#011train-error:0.094447\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[88]#011train-error:0.094482\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[89]#011train-error:0.094378\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 28 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[90]#011train-error:0.094343\u001b[0m\n",
      "\u001b[34m[91]#011train-error:0.094274\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 28 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[92]#011train-error:0.094239\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 32 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[93]#011train-error:0.094169\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[94]#011train-error:0.094169\u001b[0m\n",
      "\u001b[34m[23:26:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[95]#011train-error:0.094204\u001b[0m\n",
      "\u001b[34m[23:26:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 28 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[96]#011train-error:0.094204\u001b[0m\n",
      "\u001b[34m[23:26:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[97]#011train-error:0.093927\u001b[0m\n",
      "\u001b[34m[23:26:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[98]#011train-error:0.093927\u001b[0m\n",
      "\u001b[34m[23:26:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 32 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[99]#011train-error:0.093892\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-04-20 23:26:46 Uploading - Uploading generated training model\n",
      "2021-04-20 23:26:46 Completed - Training job completed\n",
      "Training seconds: 62\n",
      "Billable seconds: 62\n"
     ]
    }
   ],
   "source": [
    "xgb.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-bolivia",
   "metadata": {},
   "source": [
    "## Deploy the trained model\n",
    "\n",
    "Deploy the trained model on a server and create a SageMaker endpoint for access (this takes a while to run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "physical-selling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-protein",
   "metadata": {},
   "source": [
    "Create predictions: reformat and load the test data, then run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "noticed-influence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12357,)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "test_data_array = test_data.drop(['y_no', 'y_yes'], axis=1).values    # Load the data into an array\n",
    "xgb_predictor.serializer = CSVSerializer()                            # Set the serializer type\n",
    "predictions = xgb_predictor.predict(test_data_array).decode('utf-8')  # Generate predictions\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',')           # Turn prediction into an array\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-wallpaper",
   "metadata": {},
   "source": [
    "## Evaluate model performance\n",
    "\n",
    "Compare the actual vs. predicted values in a table called a **confusion matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "colored-repository",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Classification Rate: 89.5%\n",
      "\n",
      "Predicted      No Purchase    Purchase\n",
      "Observed\n",
      "No Purchase    90% (10769)    37% (167)\n",
      "Purchase        10% (1133)     63% (288) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions_array), rownames=['Observed'], colnames=['Predicted'])\n",
    "tn = cm.iloc[0,0]; fn = cm.iloc[1,0]; tp = cm.iloc[1,1]; fp = cm.iloc[0,1]\n",
    "p = (tp+tn)/(tp+tn+fp+fn)*100\n",
    "print(\"\\n{0:<20}{1:<4.1f}%\\n\".format(\"Overall Classification Rate: \", p))\n",
    "print(\"{0:<15}{1:<15}{2:>8}\".format(\"Predicted\", \"No Purchase\", \"Purchase\"))\n",
    "print(\"Observed\")\n",
    "print(\"{0:<15}{1:<2.0f}% ({2:<}){3:>6.0f}% ({4:<})\".format(\"No Purchase\", tn/(tn+fn)*100,tn, fp/(tp+fp)*100, fp))\n",
    "print(\"{0:<16}{1:<1.0f}% ({2:<}){3:>7.0f}% ({4:<}) \\n\".format(\"Purchase\", fn/(tn+fn)*100,fn, tp/(tp+fp)*100, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-judgment",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Terminate the resources used:\n",
    "\n",
    "- Delete your endpoint\n",
    "- Delete training artifacts and S3 bucket\n",
    "- Delete SageMaker notebook (in the SageMaker console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "external-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the endpoint\n",
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "patent-presentation",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the DescribeEndpointConfig operation: Could not find endpoint configuration \"arn:aws:sagemaker:us-east-1:288637950667:endpoint-config/xgboost-2021-04-20-23-27-15-560\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fbc019b7c80a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Delete the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgb_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mdelete_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mrequest_failed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mfailed_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mcurrent_model_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_model_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurrent_model_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36m_get_model_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mcurrent_endpoint_config_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_endpoint_config_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         endpoint_config = self.sagemaker_session.sagemaker_client.describe_endpoint_config(\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mEndpointConfigName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_endpoint_config_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m         )\n\u001b[1;32m    506\u001b[0m         \u001b[0mproduction_variants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ProductionVariants\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the DescribeEndpointConfig operation: Could not find endpoint configuration \"arn:aws:sagemaker:us-east-1:288637950667:endpoint-config/xgboost-2021-04-20-23-27-15-560\"."
     ]
    }
   ],
   "source": [
    "# Delete the model\n",
    "xgb_predictor.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "saving-princeton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ResponseMetadata': {'RequestId': 'EVGYM6ECXKYSBMR7',\n",
       "   'HostId': 'Cij+Zh3rO+L/28Rom+AFD9VFWJ3laPCqiA7FUFsiw/zWrcFOxwPpvBQCdZ4YJGR07TvM5D9gdPU=',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amz-id-2': 'Cij+Zh3rO+L/28Rom+AFD9VFWJ3laPCqiA7FUFsiw/zWrcFOxwPpvBQCdZ4YJGR07TvM5D9gdPU=',\n",
       "    'x-amz-request-id': 'EVGYM6ECXKYSBMR7',\n",
       "    'date': 'Wed, 21 Apr 2021 00:06:12 GMT',\n",
       "    'content-type': 'application/xml',\n",
       "    'transfer-encoding': 'chunked',\n",
       "    'server': 'AmazonS3',\n",
       "    'connection': 'close'},\n",
       "   'RetryAttempts': 0},\n",
       "  'Deleted': [{'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-22-55-51-729/profiler-output/system/incremental/2021042022/1618959540.algo-1.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-23-23-00-555/profiler-output/system/incremental/2021042023/1618961160.algo-1.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-22-55-51-729/rule-output/ProfilerReport-1618959351/profiler-output/profiler-reports/BatchSize.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-23-23-00-555/output/model.tar.gz'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-23-23-00-555/rule-output/ProfilerReport-1618960980/profiler-output/profiler-reports/MaxInitializationTime.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-23-23-00-555/rule-output/ProfilerReport-1618960980/profiler-output/profiler-reports/LoadBalancing.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-23-23-00-555/rule-output/ProfilerReport-1618960980/profiler-output/profiler-report.ipynb'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-22-55-51-729/rule-output/ProfilerReport-1618959351/profiler-output/profiler-reports/LowGPUUtilization.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-23-23-00-555/profiler-output/system/incremental/2021042023/1618961100.algo-1.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-23-23-00-555/rule-output/ProfilerReport-1618960980/profiler-output/profiler-reports/OverallSystemUsage.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-22-55-51-729/rule-output/ProfilerReport-1618959351/profiler-output/profiler-reports/GPUMemoryIncrease.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-22-55-51-729/rule-output/ProfilerReport-1618959351/profiler-output/profiler-report.ipynb'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-23-23-00-555/rule-output/ProfilerReport-1618960980/profiler-output/profiler-reports/CPUBottleneck.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-22-55-51-729/rule-output/ProfilerReport-1618959351/profiler-output/profiler-reports/LoadBalancing.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-22-55-51-729/profiler-output/system/incremental/2021042022/1618959480.algo-1.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-22-55-51-729/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-23-23-00-555/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-23-23-00-555/rule-output/ProfilerReport-1618960980/profiler-output/profiler-reports/LowGPUUtilization.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-23-23-00-555/rule-output/ProfilerReport-1618960980/profiler-output/profiler-reports/BatchSize.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/train/train.csv'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-22-55-51-729/rule-output/ProfilerReport-1618959351/profiler-output/profiler-reports/OverallFrameworkMetrics.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-23-23-00-555/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-23-23-00-555/rule-output/ProfilerReport-1618960980/profiler-output/profiler-reports/GPUMemoryIncrease.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-23-23-00-555/rule-output/ProfilerReport-1618960980/profiler-output/profiler-report.html'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-22-55-51-729/rule-output/ProfilerReport-1618959351/profiler-output/profiler-reports/IOBottleneck.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-22-55-51-729/rule-output/ProfilerReport-1618959351/profiler-output/profiler-report.html'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-22-55-51-729/output/model.tar.gz'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-23-23-00-555/rule-output/ProfilerReport-1618960980/profiler-output/profiler-reports/StepOutlier.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-22-55-51-729/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-23-23-00-555/rule-output/ProfilerReport-1618960980/profiler-output/profiler-reports/Dataloader.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-23-23-00-555/rule-output/ProfilerReport-1618960980/profiler-output/profiler-reports/IOBottleneck.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-23-23-00-555/rule-output/ProfilerReport-1618960980/profiler-output/profiler-reports/OverallFrameworkMetrics.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-22-55-51-729/rule-output/ProfilerReport-1618959351/profiler-output/profiler-reports/CPUBottleneck.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-22-55-51-729/rule-output/ProfilerReport-1618959351/profiler-output/profiler-reports/OverallSystemUsage.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-22-55-51-729/rule-output/ProfilerReport-1618959351/profiler-output/profiler-reports/Dataloader.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-22-55-51-729/rule-output/ProfilerReport-1618959351/profiler-output/profiler-reports/StepOutlier.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2021-04-20-22-55-51-729/rule-output/ProfilerReport-1618959351/profiler-output/profiler-reports/MaxInitializationTime.json'}]}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete training artifacts and bucket\n",
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-strip",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
